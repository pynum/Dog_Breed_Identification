# -*- coding: utf-8 -*-
"""DogBreedPrj

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ys3vTEr1N075S_F_qn2q70FhBSPwh7FO
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install keras

# Importing library
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from tqdm import tqdm
from tensorflow.keras.preprocessing.image import load_img
from tensorflow.keras.preprocessing.image import img_to_array
from sklearn.preprocessing import label_binarize
from sklearn.model_selection import train_test_split
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D
from keras.optimizers import Adam

import zipfile
with zipfile.ZipFile('/content/drive/MyDrive/project/Copy of archive.zip', 'r') as zip_ref:
    zip_ref.extractall('pd')

# Read the labels.csv file and check shape and records
labels_all = pd.read_csv('/content/pd/labels.csv')
print(labels_all.shape)
labels_all.head()

# Loading number or each breed
breed_all = labels_all['breed']
breed_count = breed_all.value_counts()
breed_count.head(10222)

CLASS_NAME = ['scottish_deerhound', 'maltese_dog', 'afghan_hound', 'entlebucher', 'bernese_mountain_dog','golden_retriever','brabancon_griffon','komondor','eskimo_dog ','dingo' ]
labels = labels_all[(labels_all['breed'].isin(CLASS_NAME))]
labels = labels.reset_index()
labels.head(10222)

# Creating numpy matrix with zeros
X_data = np.zeros((len(labels), 224, 224, 3), dtype='float32')
# One hot encoding
Y_data = label_binarize(labels['breed'], classes = CLASS_NAME)

# Reading and converting image to numpy array and normalizing dataset
for i in tqdm(range(len(labels))):
    img = load_img('/content/pd/train/%s.jpg' % labels['id'][i], target_size=(224, 224))
    img = img_to_array(img)
    x = np.expand_dims(img.copy(), axis=0)
    X_data[i] = x / 255.0

# Printing train image and one hot encode shape & size
print('\nTrain Images shape: ',X_data.shape,' size: {:,}'.format(X_data.size))
print('One-hot encoded output shape: ',Y_data.shape,' size: {:,}'.format(Y_data.size))

# Building the Model
model = Sequential()

model.add(Conv2D(filters = 64, kernel_size = (5,5), activation ='relu', input_shape = (224,224,3)))
model.add(MaxPool2D(pool_size=(2,2)))

model.add(Conv2D(filters = 32, kernel_size = (3,3), activation ='relu', kernel_regularizer = 'l2'))
model.add(MaxPool2D(pool_size=(2,2)))

model.add(Conv2D(filters = 16, kernel_size = (7,7), activation ='relu', kernel_regularizer = 'l2'))
model.add(MaxPool2D(pool_size=(2,2)))

model.add(Conv2D(filters = 8, kernel_size = (5,5), activation ='relu', kernel_regularizer = 'l2'))
model.add(MaxPool2D(pool_size=(2,2)))

model.add(Flatten())
model.add(Dense(128, activation = "relu", kernel_regularizer = 'l2'))
model.add(Dense(64, activation = "relu", kernel_regularizer = 'l2'))
model.add(Dense(len(CLASS_NAME), activation = "softmax"))

model.compile(loss = 'categorical_crossentropy', optimizer = Adam(0.0001),metrics=['accuracy'])

model.summary()

# Splitting the data set into training and testing data sets
X_train_and_val, X_test, Y_train_and_val, Y_test = train_test_split(X_data, Y_data, test_size = 0.1)
# Splitting the training data set into training and validation data sets
X_train, X_val, Y_train, Y_val = train_test_split(X_train_and_val, Y_train_and_val, test_size = 0.2)

# Training the model
epochs = 100
batch_size = 128

history = model.fit(X_train, Y_train, batch_size = batch_size, epochs = epochs, validation_data = (X_val, Y_val))

import matplotlib.pyplot as plt
import matplotlib.image as mpimg
import numpy as np
from tensorflow.keras.preprocessing.image import load_img, img_to_array

# Specify the path of the image
image_path = '/content/pd/train/001513dfcb2ffafc82cccf4d8bbaba97.jpg'

# Read the image
image = mpimg.imread(image_path)

# Plot the image
plt.imshow(image)
plt.show()

# Preprocess the image to match the input shape expected by the model
image = load_img(image_path, target_size=(224, 224))
image = img_to_array(image) / 255.0
image = np.expand_dims(image, axis=0)

# Make predictions using the trained model
Y_pred = model.predict(image)

# Get the predicted breed label
predicted_label_index = np.argmax(Y_pred)
predicted_breed = CLASS_NAME[predicted_label_index]

# Get the original breed label
image_index = labels[labels['id'] == '001513dfcb2ffafc82cccf4d8bbaba97'].index[0]
original_label_index = np.argmax(Y_data[image_index])
original_breed = CLASS_NAME[original_label_index]

# # Decode the predictions
# predicted_breed = labels['breed'][np.argmax(Y_pred)]
# original_breed = labels['breed'][np.argmax(Y_data[0])]

# Display the original and predicted breed
print("Originally: ", original_breed)
print("Predicted: ", predicted_breed)

# Plot the training history
plt.figure(figsize=(12, 5))
plt.plot(history.history['accuracy'], color='r')
plt.plot(history.history['val_accuracy'], color='b')
plt.title('Model Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epochs')
plt.legend(['train', 'val'])

plt.show()

Y_pred = model.predict(X_test)
score = model.evaluate(X_test, Y_test)
print('Accuracy over the test set: \n ', round((score[1]*100), 2), '%')
